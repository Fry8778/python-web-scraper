from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, TimeoutException  # üîÑ –ó–ú–Ü–ù–ò –í–ù–ï–°–ï–ù–û –¢–£–¢
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import time
import re

# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª—ñ–∫–∞—Ç–∏
unique_products = set()

def is_duplicate(product_name):
    if product_name in unique_products:
        return True
    unique_products.add(product_name)
    return False

def matches_filter(product_name):
    keywords = ["–ú–ï–õ–ï–ù–ê", "–ú–ï–õ"]  
    cleaned_name = re.sub(r"[^\w\s]", "", product_name)
    return any(keyword.lower() in cleaned_name.lower() for keyword in keywords)

# üîÑ –ó–ú–Ü–ù–ò –í–ù–ï–°–ï–ù–û –¢–£–¢: –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –±–µ–∑–ø–µ—á–Ω–æ–≥–æ –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –µ–ª–µ–º–µ–Ω—Ç–∞
def get_element_safe(driver, locator, retries=3):
    for attempt in range(retries):
        try:
            return driver.find_element(*locator)
        except StaleElementReferenceException:
            print(f"‚ö° –°–ø—Ä–æ–±–∞ {attempt + 1} - –µ–ª–µ–º–µ–Ω—Ç –∑–∞—Å—Ç–∞—Ä—ñ–≤. –ü–æ–≤—Ç–æ—Ä—é—é...")
            time.sleep(1)
    return None

# üîÑ –ó–ú–Ü–ù–ò –í–ù–ï–°–ï–ù–û –¢–£–¢: –î–æ–¥–∞–Ω–æ WebDriverWait –¥–ª—è –æ—á—ñ–∫—É–≤–∞–Ω–Ω—è –µ–ª–µ–º–µ–Ω—Ç—ñ–≤
def scrape_page(driver, quotes):
    try:
        WebDriverWait(driver, 15).until(
            EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".sf-product-card__wrapper"))
        )
        product_cards = driver.find_elements(By.CSS_SELECTOR, ".sf-product-card__wrapper")
        
        for product_card in product_cards:
            for attempt in range(3):  # üîÑ –ó–ú–Ü–ù–ò –í–ù–ï–°–ï–ù–û –¢–£–¢: –°–ø—Ä–æ–±–∏ –ø—Ä–∏ StaleElementReferenceException
                try:
                    try:
                        out_of_stock_element = product_card.find_element(
                            By.CSS_SELECTOR, ".sf-product-card--out-of-stock-container")
                        print(f"[–õ–û–ì] –ü—Ä–æ–ø—É—â–µ–Ω–æ (–≤—ñ–¥—Å—É—Ç–Ω—ñ–π –Ω–∞ —Å–∫–ª–∞–¥—ñ): {product_card.find_element(By.CSS_SELECTOR, '.sf-product-card__title').text.strip()}")
                        continue
                    except NoSuchElementException:
                        pass

                    product_name_element = WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, ".sf-product-card__title"))
                    )  # üîÑ –ó–ú–Ü–ù–ò –í–ù–ï–°–ï–ù–û –¢–£–¢

                    product_name = product_name_element.text.strip()
                    
                    if is_duplicate(product_name):
                        print(f"[–õ–û–ì] –î—É–±–ª—ñ–∫–∞—Ç –ø—Ä–æ–ø—É—â–µ–Ω–æ: {product_name}")
                        continue
                    
                    if not matches_filter(product_name):
                        print(f"[–õ–û–ì] –ü—Ä–æ–ø—É—â–µ–Ω–æ —á–µ—Ä–µ–∑ –Ω–µ–≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å —Ñ—ñ–ª—å—Ç—Ä—É: {product_name}")
                        continue

                    # üîÑ –ó–ú–Ü–ù–ò –í–ù–ï–°–ï–ù–û –¢–£–¢: –û–±—Ä–æ–±–∫–∞ StaleElementReferenceException –ø—Ä–∏ –æ—Ç—Ä–∏–º–∞–Ω–Ω—ñ —Ü—ñ–Ω
                    def get_price(selector):
                        try:
                            return product_card.find_element(By.CSS_SELECTOR, selector).text.strip().replace("–≥—Ä–Ω", "").replace(",", ".")
                        except NoSuchElementException:
                            return ""

                    special_price = get_price(".sf-price__special")
                    old_price = get_price(".sf-price__old")
                    regular_price = "" if special_price else get_price(".sf-price__regular")

                    discount_percentage = ""
                    try:
                        discount_elements = product_card.find_elements(By.CSS_SELECTOR, ".sf-product-card__badge_text")
                        for element in discount_elements:
                            text = element.text.strip()
                            if "%" in text:
                                discount_percentage = text.split()[0].replace("-", "").replace("%", "")
                                break
                    except NoSuchElementException:
                        pass

                    print(f"[–õ–û–ì] –¶—ñ–Ω–∞ —Ç–æ–≤–∞—Ä—É (—Ä–µ–≥—É–ª—è—Ä–Ω–∞): {regular_price} –≥—Ä–Ω")
                    print(f"[–õ–û–ì] –¶—ñ–Ω–∞ —Ç–æ–≤–∞—Ä—É (–∑—ñ –∑–Ω–∏–∂–∫–æ—é): {special_price} –≥—Ä–Ω")
                    print(f"[–õ–û–ì] –°—Ç–∞—Ä–∞ —Ü—ñ–Ω–∞ —Ç–æ–≤–∞—Ä—É: {old_price} –≥—Ä–Ω")
                    print(f"[–õ–û–ì] –í—ñ–¥—Å–æ—Ç–æ–∫ –∑–Ω–∏–∂–∫–∏: {discount_percentage}%")

                    quotes.append([
                        product_name,
                        f"{regular_price} –≥—Ä–Ω" if regular_price else "",
                        f"{special_price} –≥—Ä–Ω" if special_price else "",
                        f"{old_price} –≥—Ä–Ω" if old_price else "",
                        f"{discount_percentage}%" if discount_percentage else ""
                    ])

                    print(f"[–õ–û–ì] –î–æ–¥–∞–Ω–æ: {product_name}")
                    break  # –Ø–∫—â–æ —É—Å–ø—ñ—à–Ω–æ - –≤–∏—Ö—ñ–¥ —ñ–∑ —Ü–∏–∫–ª—É —Å–ø—Ä–æ–±

                except StaleElementReferenceException:
                    print("‚ö° –ï–ª–µ–º–µ–Ω—Ç –∑–∞—Å—Ç–∞—Ä—ñ–≤ –ø—ñ–¥ —á–∞—Å –æ–±—Ä–æ–±–∫–∏. –°–ø—Ä–æ–±–∞ –∑–Ω–æ–≤—É...")
                    time.sleep(1)

    except TimeoutException:
        print("‚ö° –ß–∞—Å –æ—á—ñ–∫—É–≤–∞–Ω–Ω—è –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ –º–∏–Ω—É–≤. –°—Ç–æ—Ä—ñ–Ω–∫–∞ –º–æ–≥–ª–∞ –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏—Å—è.")
    except Exception as e:
        print(f"[–õ–û–ì] –ó–∞–≥–∞–ª—å–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {type(e).__name__}, {e}")

    return quotes

# –û—Å–Ω–æ–≤–Ω–∏–π –∫–æ–¥
base_url = 'https://varus.ua/dnipro/kava-zernova~typ-kavy_melena'
options = webdriver.ChromeOptions()
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')

with webdriver.Chrome(options=options) as driver:
    driver.get(base_url)
    quotes = []
    page_number = 1

    while True:
        print(f"[–õ–û–ì] –û–±—Ä–æ–±–ª—è—î—Ç—å—Å—è —Å—Ç–æ—Ä—ñ–Ω–∫–∞ {page_number}.")
        quotes = scrape_page(driver, quotes)

        try:
            next_page_link = None
            pagination_links = driver.find_elements(By.CSS_SELECTOR, ".sf-pagination__item")

            for link in pagination_links:
                if link.text.strip() == str(page_number + 1):
                    next_page_link = link.get_attribute("href")
                    break

            if not next_page_link:
                print("[–õ–û–ì] –ù–∞—Å—Ç—É–ø–Ω–æ—ó —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –Ω–µ–º–∞—î. –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—è.")
                break

            print(f"[–õ–û–ì] –ü–µ—Ä–µ—Ö–æ–¥–∂—É –¥–æ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ {page_number + 1}: {next_page_link}")
            driver.get(next_page_link)
            time.sleep(3)
            page_number += 1

        except NoSuchElementException:
            print("[–õ–û–ì] –ù–∞—Å—Ç—É–ø–Ω–æ—ó —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ó–∞–≤–µ—Ä—à–µ–Ω–Ω—è.")
            break

    if quotes:
        header = ['–ù–∞–∑–≤–∞ —Ç–æ–≤–∞—Ä—É',
                  '–¶—ñ–Ω–∞ —Ç–æ–≤–∞—Ä—É (–≥—Ä–Ω)',
                  '–¶—ñ–Ω–∞ —Ç–æ–≤–∞—Ä—É –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –∑–Ω–∏–∂–∫–∏ (–≥—Ä–Ω)',
                  '–°—Ç–∞—Ä–∞ —Ü—ñ–Ω–∞ —Ç–æ–≤–∞—Ä—É(–≥—Ä–Ω)',
                  '–í—ñ–¥—Å–æ—Ç–æ–∫ –∑–Ω–∏–∂–∫–∏ (%)']
        quotes.sort(key=lambda x: x[0])
        df = pd.DataFrame(quotes, columns=header)
        df.to_excel('scraper_selenium_Varus_melena_test1.xlsx', index=False)
        print("[–õ–û–ì] –î–∞–Ω—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É 'scraper_selenium_Varus_melena_test1.xlsx'")
    else:
        print("[–õ–û–ì] –î–∞–Ω—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        
        
          # if quotes:
    #     df = pd.DataFrame(quotes, columns=[ '–ù–∞–∑–≤–∞ —Ç–æ–≤–∞—Ä—É',
    #                                         '–¶—ñ–Ω–∞ —Ç–æ–≤–∞—Ä—É (–≥—Ä–Ω)',
    #                                         '–¶—ñ–Ω–∞ —Ç–æ–≤–∞—Ä—É –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –∑–Ω–∏–∂–∫–∏ (–≥—Ä–Ω)',
    #                                         '–°—Ç–∞—Ä–∞ —Ü—ñ–Ω–∞ —Ç–æ–≤–∞—Ä—É(–≥—Ä–Ω)',
    #                                         '–í—ñ–¥—Å–æ—Ç–æ–∫ –∑–Ω–∏–∂–∫–∏ (%)'
    #     ])
    #     df.to_excel('scraper_selenium_Varus_melena_test.xlsx', index=False)
    #     print("[–õ–û–ì] –î–∞–Ω—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É 'scraper_selenium_Varus_melena_test.xlsx'")
    # else:
    #     print("[–õ–û–ì] –î–∞–Ω—ñ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")

